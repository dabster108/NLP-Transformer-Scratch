# main.py - Deep Neural Network for MNIST Digit Classification
"""
Deep Neural Network Implementation from Scratch

This project demonstrates building a deep neural network from scratch using only NumPy
to classify handwritten digits from the MNIST dataset. The network supports multiple
hidden layers and showcases fundamental deep learning concepts.

Key Features:
- Multi-layer perceptron with customizable architecture
- Xavier weight initialization for better convergence
- ReLU activation for hidden layers, Softmax for output
- Cross-entropy loss with backpropagation
- Training visualization and model persistence
- Comprehensive prediction analysis

Author: Dikshanta
Date: November 2025
"""

import numpy as np
import matplotlib.pyplot as plt
from neural import DeepNeuralNetwork, load_mnist_data, visualize_samples, analyze_predictions
import time
import os

def main():
    """Main function to train and test the deep neural network"""
    
    print("ğŸ§  Deep Neural Network for MNIST Digit Classification")
    print("=" * 60)
    print("Building a neural network from scratch using NumPy!")
    print()
    
    # =============================================
    # Step 1: Load and Explore the Dataset
    # =============================================
    print("ğŸ“Š STEP 1: Loading MNIST Dataset")
    print("-" * 40)
    
    try:
        X_train, X_test, y_train, y_test = load_mnist_data()
        print("âœ… Dataset loaded successfully!")
        print()
        
        # Visualize some sample images
        print("ğŸ–¼ï¸  Sample images from the dataset:")
        visualize_samples(X_train, y_train, num_samples=10)
        
    except Exception as e:
        print(f"âŒ Error loading dataset: {e}")
        print("Make sure you have internet connection for downloading MNIST dataset.")
        return
    
    # =============================================
    # Step 2: Design Network Architecture
    # =============================================
    print("ğŸ—ï¸  STEP 2: Designing Network Architecture")
    print("-" * 40)
    
    # Define network architecture
    input_size = 784    # 28x28 pixels flattened
    hidden1_size = 128  # First hidden layer
    hidden2_size = 64   # Second hidden layer
    hidden3_size = 32   # Third hidden layer
    output_size = 10    # 10 digit classes (0-9)
    
    layer_sizes = [input_size, hidden1_size, hidden2_size, hidden3_size, output_size]
    
    print(f"Network Architecture:")
    print(f"  Input Layer:     {input_size} neurons (28x28 pixels)")
    print(f"  Hidden Layer 1:  {hidden1_size} neurons (ReLU)")
    print(f"  Hidden Layer 2:  {hidden2_size} neurons (ReLU)")
    print(f"  Hidden Layer 3:  {hidden3_size} neurons (ReLU)")
    print(f"  Output Layer:    {output_size} neurons (Softmax)")
    print(f"  Total Parameters: {calculate_parameters(layer_sizes):,}")
    print()
    
    # =============================================
    # Step 3: Initialize and Train the Model
    # =============================================
    print("ğŸš€ STEP 3: Training the Neural Network")
    print("-" * 40)
    
    # Create the model
    model = DeepNeuralNetwork(
        layer_sizes=layer_sizes,
        learning_rate=0.01,
        random_seed=42
    )
    
    # Training parameters
    epochs = 500
    print_interval = 50
    
    print(f"Training Configuration:")
    print(f"  Epochs: {epochs}")
    print(f"  Learning Rate: {model.learning_rate}")
    print(f"  Batch Size: Full batch")
    print(f"  Optimizer: Gradient Descent")
    print()
    
    # Start training
    print("ğŸ”„ Training in progress...")
    start_time = time.time()
    
    # Use a subset for faster training (you can use full dataset for better results)
    train_subset = 10000  # Use first 10k samples for demo
    X_train_subset = X_train[:train_subset]
    y_train_subset = y_train[:train_subset]
    
    # Train the model
    model.train(
        X_train_subset, y_train_subset,
        X_val=X_test[:1000],  # Use first 1k test samples for validation
        Y_val=y_test[:1000],
        epochs=epochs,
        print_cost=True,
        print_interval=print_interval
    )
    
    training_time = time.time() - start_time
    print(f"\nâœ… Training completed in {training_time:.2f} seconds!")
    print()
    
    # =============================================
    # Step 4: Evaluate Model Performance
    # =============================================
    print("ğŸ“ˆ STEP 4: Model Evaluation")
    print("-" * 40)
    
    # Calculate accuracies
    train_accuracy = model.accuracy(X_train_subset, y_train_subset)
    test_accuracy = model.accuracy(X_test, y_test)
    
    print(f"ğŸ“Š Performance Metrics:")
    print(f"  Training Accuracy:   {train_accuracy:.4f} ({train_accuracy*100:.2f}%)")
    print(f"  Test Accuracy:       {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    print(f"  Training Samples:    {train_subset:,}")
    print(f"  Test Samples:        {len(X_test):,}")
    print()
    
    # =============================================
    # Step 5: Visualize Training Progress
    # =============================================
    print("ğŸ“‰ STEP 5: Training Visualization")
    print("-" * 40)
    
    print("ğŸ¯ Displaying training history...")
    model.plot_training_history()
    
    # =============================================
    # Step 6: Analyze Predictions
    # =============================================
    print("ğŸ” STEP 6: Prediction Analysis")
    print("-" * 40)
    
    print("ğŸ–¼ï¸  Analyzing model predictions on test samples...")
    analyze_predictions(model, X_test, y_test, num_samples=10)
    
    # =============================================
    # Step 7: Save the Model
    # =============================================
    print("ğŸ’¾ STEP 7: Saving the Model")
    print("-" * 40)
    
    model_path = "mnist_deep_model.pkl"
    model.save_model(model_path)
    print(f"âœ… Model saved as '{model_path}'")
    print()
    
    # =============================================
    # Step 8: Demonstrate Model Loading
    # =============================================
    print("ğŸ”„ STEP 8: Model Loading Demo")
    print("-" * 40)
    
    # Create a new model and load the saved weights
    new_model = DeepNeuralNetwork(layer_sizes=layer_sizes)
    new_model.load_model(model_path)
    
    # Verify the loaded model works
    loaded_accuracy = new_model.accuracy(X_test[:1000], y_test[:1000])
    print(f"âœ… Loaded model accuracy: {loaded_accuracy:.4f}")
    print()
    
    # =============================================
    # Summary and Next Steps
    # =============================================
    print("ğŸ‰ PROJECT SUMMARY")
    print("=" * 60)
    print(f"âœ… Successfully built and trained a {len(layer_sizes)}-layer neural network")
    print(f"âœ… Achieved {test_accuracy*100:.2f}% accuracy on MNIST digit classification")
    print(f"âœ… Implemented from scratch using only NumPy")
    print(f"âœ… Training time: {training_time:.2f} seconds")
    print()
    
    print("ğŸš€ NEXT STEPS TO IMPROVE:")
    print("1. ğŸ”§ Add different optimizers (Adam, RMSprop)")
    print("2. ğŸ“ Implement regularization (L2, Dropout)")
    print("3. ğŸ¯ Add batch normalization")
    print("4. ğŸ“Š Try different activation functions")
    print("5. ğŸ¨ Add convolutional layers for better image processing")
    print("6. ğŸ“ˆ Implement learning rate scheduling")
    print()
    
    print("ğŸ’¡ Key Concepts Demonstrated:")
    print("â€¢ Forward propagation through multiple layers")
    print("â€¢ Backpropagation with chain rule")
    print("â€¢ Xavier weight initialization")
    print("â€¢ Softmax activation for multi-class classification")
    print("â€¢ Cross-entropy loss function")
    print("â€¢ Model persistence and loading")
    print()


def calculate_parameters(layer_sizes):
    """Calculate total number of parameters in the network"""
    total_params = 0
    for i in range(1, len(layer_sizes)):
        # Weights + biases
        total_params += layer_sizes[i-1] * layer_sizes[i] + layer_sizes[i]
    return total_params


def interactive_prediction():
    """Interactive function to test the model on specific digits"""
    print("\nğŸ® INTERACTIVE PREDICTION MODE")
    print("-" * 40)
    
    # Load the saved model
    try:
        model = DeepNeuralNetwork(layer_sizes=[784, 128, 64, 32, 10])
        model.load_model("mnist_deep_model.pkl")
        
        # Load test data
        _, X_test, _, y_test = load_mnist_data()
        
        while True:
            try:
                idx = input("\nEnter test sample index (0-13999) or 'q' to quit: ")
                if idx.lower() == 'q':
                    break
                
                idx = int(idx)
                if 0 <= idx < len(X_test):
                    # Make prediction
                    sample = X_test[idx:idx+1]
                    prediction = model.predict(sample)[0]
                    probabilities = model.predict_proba(sample)[0]
                    true_label = np.argmax(y_test[idx])
                    
                    # Display image
                    plt.figure(figsize=(6, 4))
                    plt.subplot(1, 2, 1)
                    plt.imshow(sample.reshape(28, 28), cmap='gray')
                    plt.title(f'True: {true_label}, Predicted: {prediction}')
                    plt.axis('off')
                    
                    # Display probability distribution
                    plt.subplot(1, 2, 2)
                    plt.bar(range(10), probabilities)
                    plt.title('Prediction Probabilities')
                    plt.xlabel('Digit')
                    plt.ylabel('Probability')
                    plt.xticks(range(10))
                    
                    plt.tight_layout()
                    plt.show()
                    
                    print(f"Prediction: {prediction} (Confidence: {probabilities[prediction]:.3f})")
                    
                else:
                    print("Index out of range! Please enter a number between 0 and 13999.")
                    
            except ValueError:
                print("Invalid input! Please enter a number or 'q' to quit.")
            except KeyboardInterrupt:
                break
        
        print("ğŸ‘‹ Thanks for testing the model!")
        
    except FileNotFoundError:
        print("âŒ Model file not found! Please run the main training first.")


if __name__ == "__main__":
    # Run the main training and evaluation
    main()
    
    # Ask if user wants to try interactive prediction
    while True:
        try:
            choice = input("\nğŸ® Would you like to try interactive prediction? (y/n): ").lower()
            if choice == 'y':
                interactive_prediction()
                break
            elif choice == 'n':
                print("ğŸ‘‹ Goodbye! Thanks for exploring deep learning!")
                break
            else:
                print("Please enter 'y' or 'n'")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Goodbye!")
            break
